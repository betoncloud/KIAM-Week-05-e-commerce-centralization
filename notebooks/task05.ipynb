{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5: Model Interpretability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install shap lime transformers datasets\n",
    "\n",
    "# Import required libraries\n",
    "import shap\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Step 1: Load the fine-tuned model and tokenizer\n",
    "model_name = \"Davlan/xlm-roberta-base-ner-hrl\"  # Replace with your model's path or Hugging Face model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "# Create an NER pipeline\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "\n",
    "# Step 2: Load or define a dataset\n",
    "# Replace this with your dataset loading step (e.g., loading from .conll files)\n",
    "sample_texts = [\n",
    "    \"አዲስ አበባ ውስጥ እቃዎችን በዝቅተኛ ዋጋ ማግኘት ይቻላል።\",\n",
    "    \"በአዲስ አበባ የእንደቁልፍ ቤቶችን መታየት ይቻላል።\",\n",
    "    \"ኢትዮጵያ ውስጥ እቃዎችን ለእንቅስቃሴ እንደተዘጋጅቷቸው ታውቋል።\"\n",
    "]\n",
    "\n",
    "# Step 3: Interpret with SHAP\n",
    "# Wrap the model for SHAP compatibility\n",
    "def ner_predict(inputs):\n",
    "    tokenized_inputs = tokenizer(inputs, truncation=True, return_tensors=\"pt\", padding=True)\n",
    "    outputs = model(**tokenized_inputs)\n",
    "    logits = outputs.logits.detach().numpy()\n",
    "    return logits\n",
    "\n",
    "# Use SHAP explainer\n",
    "explainer = shap.Explainer(ner_predict, sample_texts)\n",
    "shap_values = explainer(sample_texts)\n",
    "\n",
    "# Visualize SHAP explanations for each text\n",
    "for i, text in enumerate(sample_texts):\n",
    "    print(f\"SHAP Explanation for Text {i + 1}:\")\n",
    "    shap.plots.text(shap_values[i])\n",
    "\n",
    "# Step 4: Interpret with LIME\n",
    "# Define a LIME-compatible prediction function\n",
    "def lime_predict(inputs):\n",
    "    results = []\n",
    "    for input_text in inputs:\n",
    "        result = ner_pipeline(input_text)\n",
    "        label_scores = {}\n",
    "        for entity in result:\n",
    "            label_scores[entity[\"entity_group\"]] = entity[\"score\"]\n",
    "        results.append(label_scores)\n",
    "    return results\n",
    "\n",
    "# Use LIME explainer\n",
    "explainer = LimeTextExplainer(class_names=model.config.id2label.values())\n",
    "\n",
    "# Explain a specific example with LIME\n",
    "text_to_explain = sample_texts[0]\n",
    "explanation = explainer.explain_instance(text_to_explain, lime_predict, num_features=6)\n",
    "explanation.show_in_notebook()\n",
    "\n",
    "# Step 5: Analyze difficult cases\n",
    "# Example of analyzing predictions\n",
    "for i, text in enumerate(sample_texts):\n",
    "    print(f\"Text {i + 1}: {text}\")\n",
    "    predictions = ner_pipeline(text)\n",
    "    print(\"Predictions:\")\n",
    "    for pred in predictions:\n",
    "        print(pred)\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Step 6: Generate interpretability report\n",
    "# Use SHAP and LIME insights to create a table (can be exported to a CSV or visualized)\n",
    "import pandas as pd\n",
    "\n",
    "report_data = []\n",
    "for text in sample_texts:\n",
    "    predictions = ner_pipeline(text)\n",
    "    for pred in predictions:\n",
    "        report_data.append({\n",
    "            \"Text\": text,\n",
    "            \"Entity\": pred[\"entity_group\"],\n",
    "            \"Word\": pred[\"word\"],\n",
    "            \"Confidence\": pred[\"score\"],\n",
    "            \"Start\": pred[\"start\"],\n",
    "            \"End\": pred[\"end\"]\n",
    "        })\n",
    "\n",
    "# Convert to a DataFrame for better visualization\n",
    "report_df = pd.DataFrame(report_data)\n",
    "print(\"Interpretability Report:\")\n",
    "print(report_df)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
