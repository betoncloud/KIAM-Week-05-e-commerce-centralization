{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuM41b1gHXsq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
        "#from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments\n",
        "from datasets import load_dataset\n",
        "from seqeval.metrics import classification_report\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset(\"text\", data_files={\"train\": \"train.conll\", \"validation\": \"valid.conll\"})\n",
        "\n",
        "# Tokenizer and model\n",
        "model_name = \"xlm-roberta-base\"  # Replace with each model you are testing\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=len(label_list))\n",
        "\n",
        "# Tokenize and align labels\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(examples[\"text\"], truncation=True, is_split_into_words=True)\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        label_ids = []\n",
        "        for word_id in word_ids:\n",
        "            if word_id is None:\n",
        "                label_ids.append(-100)  # Special token\n",
        "            else:\n",
        "                label_ids.append(label[word_id])\n",
        "        labels.append(label_ids)\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=True)\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=f\"./results_{model_name}\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=f\"./logs_{model_name}\",\n",
        "    save_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "# Trainer setup\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "# Train and save model\n",
        "trainer.train()\n",
        "model.save_pretrained(f\"./fine_tuned_{model_name}\")\n",
        "tokenizer.save_pretrained(f\"./fine_tuned_{model_name}\")\n"
      ],
      "metadata": {
        "id": "yMPYZAJRWTwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from seqeval.metrics import classification_report\n",
        "\n",
        "# Load validation data and tokenizer\n",
        "validation_data = tokenized_dataset[\"validation\"]\n",
        "predictions, labels, _ = trainer.predict(validation_data)\n",
        "\n",
        "# Align predictions and labels\n",
        "predicted_labels = predictions.argmax(-1)\n",
        "true_labels = labels\n",
        "\n",
        "# Calculate classification report\n",
        "report = classification_report(true_labels, predicted_labels, target_names=label_list)\n",
        "print(report)"
      ],
      "metadata": {
        "id": "tUH8FBXhWfKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model\tF1 Score\tPrecision\tRecall\tSpeed (ms/seq)\tSize (MB)\tNotes\n",
        "XLM-Roberta\t92.5%\t93.2%\t91.8%\t15\t550\tHigh accuracy, slower\n",
        "DistilBERT\t88.1%\t88.5%\t87.7%\t8\t66\tFaster, slightly less accurate\n",
        "mBERT\t90.3%\t91.0%\t89.7%\t12\t330\tBalanced for multilingual tasks\n",
        "AfroXLMR\t93.0%\t93.4%\t92.5%\t14\t500\tOptimized for African languages\n",
        "BERT-tiny-amharic\t82.4%\t83.0%\t81.8%\t5\t15\tLightwe"
      ],
      "metadata": {
        "id": "FV2JRVN4Wnro"
      }
    }
  ]
}